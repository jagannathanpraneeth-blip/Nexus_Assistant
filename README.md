# Nexus Assistant ğŸ¤–

**Nexus** is a **conversational, â€œbroâ€‘styleâ€ AI desktop assistant** built with Python.  
It can:

- ğŸ¤ **Listen & speak** (Windows SAPI TTS) with a casual tone.  
- ğŸ–¥ï¸ **Open, close, install, uninstall, and type** into apps (e.g., Notepad).  
- ğŸŒ **Search the web** and **play YouTube videos** (smart fallback to the official site if the app isnâ€™t installed).  
- ğŸ“¸ **Capture & summarize the screen** (visionâ€‘enabled).  
- â° **Set reminders** with naturalâ€‘language timing.  
- ğŸ–±ï¸ **Run arbitrary shell commands** (PowerShell) for â€œdoâ€‘everythingâ€ requests.  
- ğŸ’¬ **Chat naturally** â€“ greetings, small talk, and casual replies using a â€œbroâ€ persona.

## ğŸš€ Quick Start

1. **Clone the repo** (you already did)  
   ```bash
   git clone [https://github.com/jagannathanpraneeth-blip/Nexus_Assistant.git](https://github.com/jagannathanpraneeth-blip/Nexus_Assistant.git)
   cd Nexus_Assistant
   pip install -r requirements.txt
# youâ€™ll need: speechrecognition, pyautogui, aiohttp, openai (or the provider you choose), etc.
OPENAI_API_KEY=your-openai-key   # or GOOGLE_API_KEY for Gemini
LLM_PROVIDER=openai               # openai | gemini | hybrid

Set environment variables (create a 
.env
 file)
dotenv
OPENAI_API_KEY=your-openai-key   # or GOOGLE_API_KEY for Gemini
LLM_PROVIDER=openai               # openai | gemini | hybrid
Run the assistant
python main.py
Say â€œNexusâ€ (or â€œHey Nexusâ€) to wake it up.
Example commands:
Open Notepad and type hello world
Play never gonna give you up
Summarize my screen
Remind me to drink water in 5 minutes
Hey Nexus, howâ€™s it going?
ğŸ“‚ Project Structure
Nexus_Assistant/
â”œâ”€ .env                 # your secrets (gitâ€‘ignored)
â”œâ”€ .gitignore           # excludes .env, DB, __pycache__, *.pyc
â”œâ”€ main.py              # entry point â€“ starts orchestrator, brain, voice loop, GUI
â”œâ”€ core/
â”‚   â”œâ”€ orchestrator.py  # task scheduler & executor
â”‚   â”œâ”€ types.py         # Task, Event, statuses
â”‚   â””â”€ event_bus.py     # simple pub/sub system
â”œâ”€ cognitive/
â”‚   â”œâ”€ brain.py         # parses input, captures screen, creates tasks
â”‚   â””â”€ llm_interface.py # LLM wrappers (Mock, OpenAI, Gemini, Hybrid)
â”œâ”€ integrations/
â”‚   â”œâ”€ system.py        # OS actions (open app, type, screenshot, notifications)
â”‚   â”œâ”€ web_search.py    # DuckDuckGo HTML search (no API key)
â”‚   â”œâ”€ web_automation.py# YouTube search & autoâ€‘play
â”‚   â””â”€ voice.py         # speechâ€‘toâ€‘text & textâ€‘toâ€‘speech
â”œâ”€ ui/
â”‚   â”œâ”€ desktop_gui.py   # simple Tkinter window for typed commands
â”‚   â””â”€ templates/
â”‚       â””â”€ index.html   # HTML UI (if you expand to a web frontâ€‘end)
â””â”€ universal_agent.db   # tiny SQLite DB for task logging
ğŸ› ï¸ Customising the Persona
The â€œbroâ€ tone is defined in 
cognitive/llm_interface.py
 system prompt.
If you want a more formal voice, just change the prompt or set the environment variable:
export NEXUS_FORMAL=true   # (or edit the prompt directly)
ğŸ”§ Known Issues & Fixes
pyautogui / cv2 import errors â€“ resolved by running typing in a thread pool and catching the import error.
Screenâ€‘summarisation â€“ currently a mock response; replace the mock with a real vision model (e.g., OpenAIâ€™s gptâ€‘4â€‘vision).
Git secret removal â€“ 
.gitignore
 now excludes 
.env
 and the SQLite DB.
ğŸ“œ License
MIT License â€“ feel free to fork, tweak, and share!

Enjoy the vibe, bro!
If you run into any hiccups, just shout â€œNexusâ€ and ask for help. ğŸ§


Copy the whole block above into a new file named **README.md** at the root of your repository, commit, and push. Your repo will now have a nice landing page describing the project. Let me know if youâ€™d like any tweaks!
